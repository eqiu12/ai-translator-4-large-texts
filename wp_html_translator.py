"""WordPress HTML Translator â€“ Streamlit app (limitâ€‘safe + EN localisation)

Features
â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Chunked, retryâ€‘safe translation RU/EN â†’ DE/ES/FR/TR/EN  
â€¢ Domain & currency shortcode swap
â€¢ Optional QA pass (with backâ€‘off)
â€¢ **Extra localisation when target = English:**
  â€“ Replace emâ€‘dash (â€”) with normal dash (â€“) or comma  
  â€“ Use plain, nonâ€‘academic grammar  
  â€“ Convert metric lengths, areas, speeds & temps to imperial **and keep both units**

Run locally
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export OPENAI_API_KEY=â€¦  # required
pip install streamlit openai tiktoken
streamlit run wp_html_translator.py
"""

from __future__ import annotations

import re, time
from typing import List

import streamlit as st

try:
    import tiktoken  # type: ignore
except ImportError:
    st.error("Install tiktoken: pip install tiktoken")
    raise

from openai import OpenAI, RateLimitError

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

MODEL_PREF_TRANSLATE = "gpt-4-1-mini"   # falls back to gptâ€‘4o
MODEL_PREF_QA        = "gpt-4-1"
MODEL_FALLBACK       = "gpt-4o"
TOKEN_LIMIT          = 32_000          # context for gptâ€‘4o
SAFETY_MARGIN        = 0.5             # â‰¤16k tokens per chunk
MAX_RETRIES          = 5

client = OpenAI()
enc    = tiktoken.encoding_for_model(MODEL_FALLBACK)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def ensure_model(name: str, fallback: str) -> str:
    try:
        client.models.retrieve(name)
        return name
    except Exception:
        return fallback

MODEL_TRANSLATE = ensure_model(MODEL_PREF_TRANSLATE, MODEL_FALLBACK)
MODEL_QA        = ensure_model(MODEL_PREF_QA, MODEL_FALLBACK)


# Dynamic prompt builder ---------------------------------------------------

def build_system_prompt(src: str, tgt: str, old_domain: str, new_domain: str,
                        cur_from: str, cur_to: str, cur_label: str) -> str:
    common = f"""
You are a professional translator.
Translate the USERâ€‘supplied HTML from {src} to {tgt}.
Preserve ALL HTML tags, attributes, IDs, classes, comments and shortâ€‘codes â€“ edit only text nodes.
Replace image/video domain '{old_domain}' â†’ '{new_domain}'.
Inside [convert â€¦] shortâ€‘codes: change to="{cur_from}" â†’ to="{cur_to}" and replace the trailing currency word with '{cur_label}'.
Return **raw HTML only** â€“ no extra wrappers. If output would be truncated respond with TRUNCATED.
"""

    if tgt.lower().startswith("english"):
        extra = """
EXTRA RULES FOR ENGLISH TARGET
â€¢ Avoid emâ€‘dashes (â€”). Replace with normal dash (â€“) or comma as suits simple grammar.
â€¢ Write in plain, everyday US English; short sentences, no academic phrasing.
â€¢ Convert metric measurements to imperial and keep **both**:
  â€“ length & distance: km â†’ mi, m â†’ ft, cm â†’ in  (e.g. "10Â km (6Â mi)")
  â€“ area: sqÂ km â†’ sqÂ mi
  â€“ speed: km/h â†’ mph
  â€“ weight: kg â†’ lb, g â†’ oz
  â€“ temperature: Â°C â†’ Â°F (e.g. "20Â Â°C (68Â Â°F)")
  Round converted numbers sensibly (kmâ†’mi to whole number; metersâ†’feet to nearest 10â€¯ft if >300â€¯ft, otherwise 1â€¯ft). Do **not** recalculate currency.
"""
        common += extra
    return common


# Chunking -----------------------------------------------------

def split_html(html: str, limit: int = TOKEN_LIMIT, margin: float = SAFETY_MARGIN) -> List[str]:
    safe = int(limit * margin)
    ids  = enc.encode(html)
    chunks, cur = [], []
    for tok in ids:
        cur.append(tok)
        if len(cur) >= safe:
            chunks.append(enc.decode(cur))
            cur = []
    if cur:
        chunks.append(enc.decode(cur))
    return chunks

# OpenAI call helpers ------------------------------------------

def with_retry(func, *args, **kwargs):
    for attempt in range(MAX_RETRIES):
        try:
            return func(*args, **kwargs)
        except RateLimitError:
            time.sleep(2 ** attempt)
    raise RuntimeError("OpenAI call failed after retries.")


def translate_chunk(chunk: str, prompt: str) -> str:
    out = with_retry(
        client.chat.completions.create,
        model=MODEL_TRANSLATE,
        messages=[{"role": "system", "content": prompt},
                  {"role": "user",   "content": chunk}],
        temperature=0,
        top_p=0,
        response_format={"type": "text"}
    ).choices[0].message.content
    if out.strip() == "TRUNCATED":
        raise ValueError("Chunk too large â€“ lower SAFETY_MARGIN.")
    return out


def qa_pass(src_html: str, tgt_html: str, src_lang: str, tgt_lang: str) -> str:
    qa_prompt = f"""You are a bilingual proofâ€‘reader. List mistranslations or omissions between SOURCE ({src_lang}) and TARGET ({tgt_lang}). If all good, reply 'No issues found.'"""
    return with_retry(
        client.chat.completions.create,
        model=MODEL_QA,
        messages=[
            {"role": "system", "content": qa_prompt},
            {"role": "user",   "content": f"SOURCE:\n{src_html}\n\nTARGET:\n{tgt_html}"}
        ],
        temperature=0,
        top_p=0
    ).choices[0].message.content.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(page_title="WP HTML Translator", layout="wide")
st.title("ğŸ“ WP HTML Translator â€“ EN localisation & retries")

html_in = st.text_area("Input HTML", height=400)
col1, col2 = st.columns(2)
with col1:
    src_lang = st.selectbox("Source language", ["Russian", "English"])
    old_dom  = st.text_input("Old image domain", "https://samokatus.ru/wp-content/uploads/2025/07")
    cur_from = st.text_input("Currency shortcode FROM", "rub")
with col2:
    tgt_lang = st.selectbox("Target language", ["English", "German", "Spanish", "French", "Turkish"])
    new_dom  = st.text_input("New image domain", "https://tripsteer.co/wp-content/uploads/2025/07")
    cur_to   = st.text_input("Currency shortcode TO", "usd")
    cur_lbl  = st.text_input("Currency label", "USD")

run_qa = st.checkbox("Run QA pass", value=True)

if st.button("Translate"):
    if not html_in.strip():
        st.warning("Paste HTML first.")
        st.stop()
    if src_lang == tgt_lang:
        st.warning("Source and target are the same â€“ nothing to translate.")
        st.stop()

    prompt = build_system_prompt(src_lang, tgt_lang, old_dom, new_dom, cur_from, cur_to, cur_lbl)
    parts  = split_html(html_in)

    st.info(f"Translating {len(parts)} chunk(s)â€¦")
    prog = st.progress(0.)
    out_parts: List[str] = []
    for i, part in enumerate(parts, 1):
        with st.spinner(f"Chunk {i}/{len(parts)}â€¦"):
            out_parts.append(translate_chunk(part, prompt))
        prog.progress(i / len(parts))

    full_out = "\n".join(out_parts)

    if run_qa:
        st.subheader("QA pass")
        with st.spinner("Proofâ€‘readingâ€¦"):
            report = qa_pass(html_in, full_out, src_lang, tgt_lang)
        st.text_area("QA suggestions", report, height=200)

    st.success("Done âœ…")
    st.text_area("Output HTML", full_out, height=400)
    st.download_button("ğŸ’¾ Download HTML", full_out, file_name=f"translated_{tgt_lang.lower()}.html", mime="text/html")
